%% ----------------------------------------------------------------
%% Evaluation.tex
%% ---------------------------------------------------------------- 


\chapter{Evaluation} \label{Chapter:Evaluation}

The PSN system has been tested to make sure it didn’t had any bugs and it provided the correct output. The different information generated by the system is calculated by the software and gives a general statistical analysis seen in 6.1.The system has also been tested to see if it provided the correct answers and evaluated to check the quality of the answer and output it generated. The system gives a rank and value to each answer. It also gives confidence rating to the keywords based on the importance of the keywords used in the context of question and answers. The software automatically rates all these things. These ratings are needed to be verified by humans to make sure it’s correct and doesn’t have too many errors and context inaccuracies. This is done by designing an experiment to test the system in section 6.1 and the results are analyzed in section 6.2.

\section{Experiment Design}

The PSN system algorithm generates the following information from the dataset.- Keywords with degree of confidence- Answers with rank and degree of confidence- Experts with rank and degree of confidenceThe system uses the algorithm to generate all the keywords and based on the keyword matrix finds the answers and experts. These results need to be evaluated to find it’s usefulness and if it’s the right answer for the question. Experts in the programming language would be able to tell if the answer provided for the question can applied to the problem and if the users will be benefited or not with the answers.Based on the dataset we have and the information the system generates two experiments are designed to test if the keywords and the answers are of good quality or not. It’s easier to show the keywords and answers to unanswered questions to the users and ask them to rate the quality of it. Based on their own expertise, the user can tell about the validity of keywords and if the answer can satisfy the question asked. But it’s not a good test to show the name of the experts generated by the system to the user and ask then to rate their expertise, since the participants have never met the expert or seen their work. So the evaluation of the expert generator part of the system has been dropped. Only the keywords and answers are evaluated.An experiment is designed to evaluate the system. In this experiments participants are given a questionnaire that has unanswered question with two sets of keywords. One set it the already existed keywords from StackOverflow and Reddit website and the other set is the system generated keywords. Participants are then asked to rate the quality of the keywords based on the question.The other experiment evaluates the answers. In this experiment, participants are shown unanswered question and a similar question and its answer that provide solution to the unanswered question. The participants are rate to ask the quality of the answer and how effectively it answers and unanswered question.These experiments are discussed in details in the next sections.


\subsection{Calculating Sample Size}

In this experiment, to build a proper statistical model to test the system it is vital to get the range of questions, answers, keywords and user response, it’s quite important to get the right sample size of data. It is essential to test the range of quality of answers that can be applied to entire population of data. A right subset of these data can be used as a sample and correct test can be done to calculate the effectiveness of the system. 

The sample size for both the experiments (keywords and answers) are calculated using G-Power software. All the values of alpha and beta errors, standard deviation, power, etc., are the standard value used in the research community.Keyword experiment: Each value entered in G-Power to calculate the number of question sample is as follows: // Recheck the values.Test family – T testStatistical test – Means: Difference from constant (one sample case)Type of power analysis -  A priori – Compute required sample size – given alpha, power and effect size.Mean H0 = 6Mean H1 = 7Standard Deviation = 1.5Tails – TwoEffect size d = 0.6666667Alpha error probability = 0.05Power (1 – Beta error probability) = 0.9This gives the Total sample size of 26.So 26 questions are required to get the proper sample size to represent the whole population of keywords in the system.Answers experiment: Each value entered in G-Power to calculate the number of question sample is as follows: // Recheck the values.Test family – ExactStatistical test – Correlation: Bivariate normal modelType of power analysis - A priori – Compute required sample size – given alpha, power and effect size.Tails – TwoCorrelation p H1 = 0.5Alpha error probability = 0.05Power (1 – Beta error probability) = 0.95Correlation pH0 = 0This gives the Total sample size of 46.So 46 answers are required to get the proper sample size to represent the whole population of answers in the system.Participant size: Each value entered in G-Power to calculate the number of participants required to answer each question is as follows: // Recheck the values.Test family – T testStatistical test – Means: Difference from constant (one sample case)Type of power analysis - A priori – Compute required sample size – given alpha, power and effect size.Mean H0 = 6Mean H1 = 7Standard Deviation = 1.5 Tails – TwoEffect size d = 0.6666667Alpha error probability = 0.05Power (1 – Beta error probability) = 0.8This gives the Total sample size of 20.So 20 participants are required to get the proper sample size to properly evaluate the system.


\subsection{Selecting Questions}

The next part of the experiment is selecting the right questions to ask the participants. A good range of samples must be chosen that represents all the different aspects of the dataset.As calculated earlier, there needs to be 26 questions for the keywords experiment and 46 questions for the answers experiment. Each question requires 20 answers to get good and valid results.There were certain factors that needed to be considered for the questions selections procedure.- First, the University’s Ethics Committee says that an experiment can’t be longer than 1 hour.- The questions have to be short and easy to understand so the participants can finish the experiment in 1 hour.- The questions must not have any answers and must have keywords.Due to limiting time factor the keyword experiment was split into two groups. Each group would consist of 20 people and answer 15 questions. And the answers experiment was split into three groups where two groups would answer 15 questions each and the third group would answer 16 questions.Also, the since the participants needed to answer programming related question, they needed to be competent in programming and have a moderate expertise on the topic. This was determined by selecting the users who had two or more years of experience in programming with the given programming language.Java and Python programming language were chosen as these were the popular programming languages among the participants and also they are popular languages in both StackOverflow and Reddit website. These were good language to get a wide variety of questions that met the following criteria.- Topic- Questions were selected from different topics to give a wide range and variety to the subject. These were from web development, networking, mobile development, etc. Both Java and Python provides multiple and different areas where it could be used to program. This is relevant for both keyword and answers experiment.- Difficulty- The selected questions must be of various level of difficulties. It mostly fell on the three categories- easy, medium and hard. The difficulty of the question was determined by going through the content of books about learning programming languages. The beginning chapters taught easier topics, middle chapters were harder but still doable topics and later chapters are of more difficult topics. Based on this logic the unanswered questions were selected for both Java and Python. This will later be used to do more complicated statistical analysis of the results.- Quality. The final criteria was about the quality of answers presents to the unanswered questions. The algorithm that searches answers for questions gives them a rank and rate of confidence to show how good or bad the quality of answers are. The experiment wants to see the correlation between the algorithms ratings and users ratings. So, a wide range of answers were selected of different quality and they were- good, medium and bad.The algorithm is designed to give each answer a score from 0.01 to 1.00. The answers that have score of higher that 0.7 is considered good, a score between 0.4 and 0.7 is considered medium and the score less than 0.4 is considered bad.Based on all of the above criteria 15 questions from Python and 31 questions from Java were selected for participants. Since, same questions to test for answers could be used for keywords, the same 15 questions from both Python and Java were used for keywords experiments too. There was no conflict to choose the same question because the keyword test was done on only questions and two sets of keywords. One set of keywords were already collected from the website and the other set were generated by the system. Only the top 7 keywords were selected based on the highest rate of confidence. And answers experiment was done by using the same unanswered questions and a similar question with its answer.


\subsection{Questionnaire Design}
The next step of the experiment was to design the questionnaire to get user feedback to evaluate the system. The questionnaire was created online for easy access for participants and also data collection was easy and University’s survey portal known as iSurvey was used to create it. The portal made it easier to add questions and make public pages for the questionnaire, get consent and collect data into the database.For this experiment and questionnaire rating scale is used to measure the response of participant. The ratings are to measure the effectiveness of the output of the system. This helps to understand and measure the usefulness of the whole application. Keyword experiment used the scale of 1 to 5 and the answer experiment used the scale of 1 to 10. This is discussed later in much more detail.Three questionnaire were created, two Java programming language and one for Python programming language. The first Java and Python questionnaire had 15 questions to rate the quality of answers and 15 questions with two sets of keywords asking participants to rate the quality of the keywords. The last Java questionnaire only evaluated answers, not the keywords.At first a pilot experiment was done with three participants to get feedback about the questionnaire and if it could be improved. The participants provided many helpful feedbacks. After getting their recommendation, the language of the questionnaire was made much more simpler and easy to understand. The questions were made bold so it was clearer and some grammatical mistakes were fixed. The user instruction was added at the top of every question instead as the beginning of questionnaire. Also, the question occurrence for keywords was randomized.After making all the changes with the new and improved questionnaire, random participants were contacted to do the experiment. The only criteria for the participant selection were they had the knowledge of either Python or Java for at least more than two years. All the participants’ information was anonymised. The participants were asked to not search for answers but to use their own expertise to judge the quality of keywords and answers. In case they weren’t sure about the answers then they were asked to use their best guess or select the middle value of the scale.The details of each experiment are given below.

6.2.3.1 Keyword Evaluation: The participants were shown a question with the original keywords used in the website and asked to rate how well the keywords describe the question. Then the participants were shown the same question with the original plus the added keywords but they were the top 10 keywords based on the rate of confidence of each keyword. Again, the participants were asked to rate how well the new sets of keywords describe the question. All the ratings were stored in the database.Here is an example question with the instructions:Instruction for question: 1. Read the question (section A)2. Rate how well the keywords describe the question in your opinion (section B) A. Java, console.readPassword adds extra line. How to delete it?When i use console.readPassword() to read user passwords through console, there is always one line added to the console.How to disable this behavior or how to delete that extra line (and move the cursor after the last character in the line before)? What escape character to use?ThanksB. Keywords: java, console, passwordQ. Please rate how well the keywords describe the question in your opinion (section B) Very bad	1	2	3	4	5	Very good	          The keywords experiments use the rating from 1 to 5 where 1 is for very bad and 5 is for vey good. A scale of 1 to 5 was chosen because the keywords are the basis of application, the system uses the original keyword used in StackOverflow website and Reddit’s subreddit name and other keywords are added to it. The difference in keywords is visible easily. Also, only the top 10 keywords are shown to the users. This didn’t make too many alterations to the list of keywords. Participants could easily see the in the use and quality of keywords.  Also, the value given to each sets of keywords were going to be compared to other in the T-Test, for this a small scale of 1-5 could give the results with less error probability. So it was decided to use the scale from 1 to 5.In this survey the occurrence of question with original keywords and the added keywords were randomized so the participants couldn’t guess the patters at which these questions would appear. This step was taken to reduce users’ bias and was recommended by participants during the pilot program as the original questionnaire followed the same pattern of first asking the question with original keywords and second with the generated keywords.In total 30 questions were asked to evaluate keywords and each question receive 20 responses. The statistical analysis is done in the next section.6.2.3.2 Answer Evaluation: The experiment to evaluate the quality of answers consisted of the questionnaire where the participants were shown an unanswered question and then a similar question with an answer. This answer was expected to provide a solution for the first unanswered question. The participants were asked to rate the quality of the answer based on how well the answer could give a solution to the question. All the ratings were stored in the database.Here’s an example of the question and user instruction.Instruction for question: 1. Read the question in both section A and B2. Read section C that is the answer to B3. Rate how well the answer in section C also answers the question in section A in your opinion4. You are allowed to click on any links if you want.5. Please don't Google the question as it might show you StackOverflow results and its rating might influence your rating.A. Read text from PNG with standard libIs there a way to read text from a PNG-File in Python by using only the standard libraries Python provides?Similar Question:B. Python: default/common way to read png imagesI haven't found a standard way in Python to read images. Is there really none (because there are so many functions for so many custom stuff that I really wonder that there are no functions to read images)? Or what is it? (It should be available in the MacOSX standard installation and in most recent versions on Linux distributions.)If there is none, what is the most common lib?Many search results hint me to Python Imaging Library. If this is some well known Python-lib for reading images, why isn't it included in Python?Answer:C. No, there are no modules in the standard library for reading/writing/processing images directly. But the most common library might be PIL (Python Imaging Library). Many projects are not included in the standard library because they are 1) totally optional and 2) cannot be maintained by the few Python core developers.Q. Please rate how well the similar question and answer (section B and C) provide a solution to the first question (section A).Very bad12345678910Very good                    For the answers’ evaluation the scale of 1 to 10 was used where 1 was very bad and 10 was very good. The scale from 1 to 10 was chosen because the algorithm that searches for the answers gives a rank and confidence rating to the answers that lies between 0 and 1. This rank is equivalent to the users ratings and it could be used to do a Spearman correlation test to see if the user agrees with the ranking of the system.The questions that were selected had a range of difficulty from easy, medium and hard. The answers also had a range of quality from good, medium and bad. Participant’s response would give a good estimation if they agree with the system rating or not. These different types of questions were randomized so the participants can’t find the pattern in the difficulty and quality of question and answers.In total there were 46 questions and answers tested. There were two questionnaires, one in Java and other in Python with 15 questions. The third questionnaire was in the Java with 16 questions. All the questions had 20 responses from the participants. The details of the response and statistical test are discussed in the next section.

\section{Results}

After conducting the experiments with the participants their data was collected and stored in the University’s iSurvey website. The website allows the data to be downloaded in excel sheet. The data was cleaned and structured, it was used to create a frequency distribution chart. Mean value was also calculated to do the statistical analysis.These values are added to the SPSS software to do the statistical analysis. The details of all the analysis are in the following sections.


\subsection{Dataset Frequency Distribution}

A frequency distribution gives the frequency or count of all the data points for the sample. Here a general overview of the collected data is provided.The diagram below describes the frequency distribution of all the ratings for the keyword experiment. It is a normal distribution.[Diagram for keyword frequency distribution]This can be further broken down in to group, the first diagram shown the frequency distribution of the ratings of the original keywords and the second one is of the system generated keywords.[2 diagrams]It is evident from the analysis that the system-generated keywords had higher ratings than the original keywords. Further statistical analysis of keywords will be done in the next section.Similar analysis is done with the data collected from answers experiment. The diagram below shows the frequency distribution of all the responses received from the 20 responses from the 46 questions.[Q/A FD diagram]The data can be further broken down by quality and difficulty of answers. The diagram shows the difficulty of answers ??[Diagram for difficulty and quality of answers… see if it is relevant]More detailed statistical analysis of the answers are done in the section []


\subsection{Keywords T-Test}

When collected the data, it had a set of keywords from StackOverflow and Reddit website. The PSN system analyzed the text of the question and answers and added more keywords to the system. It also added additional keywords to add broader and narrower categories to each data.So, there was an original set of keywords and the added set of keywords. To evaluate the quality and usefulness of the added set of keywords the experiment was designed. Participants were shown questions and asked to rate the quality of both sets of keywords based on how well they described the questions. So, there are ratings for how well the original sets of keywords describe a question and ratings for modified sets of keywords and how well they describe the same questions. Both the ratings are for same question with little modification. They are a pair of dependent variable.Comparing the means of the ratings for the two depended pair could provide the usefulness of a certain set of keywords. This could be calculated using a dependent T-Test. So, this particular statistical test was done to figure out if the generated sets of keywords were adding more value to the questions then the original keywords. SPSS was used on the data collected during the experiment and Paired- Samples T test was performed. The analysis showed that on average the keywords generated by the system were useful and described the question better (Mean = 3.5, Standard Deviation  = 0.44, Standard Error = 0.81) than the original keywords (Mean = 3.09, Standard Deviation  = 0.88, Standard Error = 0.16). There was a significant difference in the usefulness of generated keywords than the original keywords.  T(28) = -2.254, p = 0.32, r = 0.38[diagram 1, 2, 3 of SPSS output]Effect size (r) = Square root (t2/(t2=df))  = square root ((-2.254 ^ 2) / ((-2.254 ^ 2) + 29))= sq rt ( 5.08 / 34.08)= 0.1448 = 0.38Here p <0.5 and the effect size r = 0.38 which is medium. The generated keywords add some benefit to the questions and answers. They improve in categorizing the topics and improve the search results.User data showed that users rated the system generated keywords better than the original in 63.3\% of the cases and worse in 26.6\% of the cases. A quick glance at the lower rated generated keywords shows that limitation of the system.The main drawback of the system is that is generates the keywords and link it to the DBpedia and OpenCalis dataset. If the topic doesn’t exist in the DBpedia and OpenCalis then they keywords is not linked to it and completely ignored. Limitation of those external systems is the limitation of this system. This could be overcome by using a NLP library to find more keywords and not link it to any external linked data cloud. It would help better categorization of the system.The other drawback of the system is that the data collected is a technical data. In these datasets lots of misspelling, abbreviation and initialism are used, these colloquial are easy to understand for programmers but the keywords generator find it difficult to interpret and link. Also, in some cases the keywords are linked to the wrong topic. Like in one example the keyword ‘Eclipse’ was linked to the natural phenomenon of ‘Eclipse’ not the ‘Eclipse (software)’ topic.The other limitation is that the versions of software and programming languages and topics like Python 2.7, Python 2.7.3, etc, is not individual page or topic, they are the section and subsection of bigger topics. These are harder to link to the linked data cloud.One anomaly found in the experiment data is that, one question was about solving time zone problem. The main topic of the question was time zone but the text contain name of the cities and countries. The keyword annotating algorithm linked and annotated all the cities with it’s topics and gave it a high confidence rating (92\%) and the main focus time zone only got 78\% confidence rating. Also, one question had an image attached to it that provided additional information about the questions. And there was no way to process the image and gather the information by the keyword annotator.Overall, the generated keywords performed better than the original keywords and provided addition information in regards to the questions but they have some limitation and drawback.


\subsection{Q\&A Correlation Test}

The PSN algorithm when searches for an answer for unanswered question it ranks all the results and give it’s a rate of confidence between 1 and 0. To test the usefulness of the answers, if it really does provide a solution to the unanswered question the Q&A experiment was designed.Participants were asked to rate how good the answers provided solutions to the unanswered question between 1 and 10. The questions were of all difficulty levels and thee answers were of range of quality. If there were a positive relationship between he algorithm rating and user rating then it would prove that the algorithm was searching for the right answers. For evaluating the answers an experiment was designed and all the data was collected and analyzed in SPSS. Pearson correlation test was chosen for analysis because the data values are at regular intervals and there is a linear relationship between the two variables (algorithm’s rating and participants’ rating).Pearson correlation test was performed to measure the relationship between the participants rating and PSN algorithm rating. There was a positive correlation between the two variables (r = .380, n = 46, p (two-tailed) = .009).[ spss diagram ]The correlation between the two ratings is moderately strong and the significance is < .01. A scatter plot summarizes the result in the figure below.[ scatter plot diagram] The analysis shows the algorithm is quite efficient in finding the right answers. The participants usually agree with the quality of the answers provided. The algorithm does well in finding the answers for difficult questions as well as easy questions.[ diagram to show difficulty with correlation]A quick glance at the user data shows the there are some answers that the users gave high rating but he algorithm didn’t. This could be because these questions were quite difficult and might be out of scope of the participants. They were merely guessing the answers and the answers looked valid.Also, there is a case where the participants gave poor rating to the answer but the algorithm gave it a high rating. Looking at the question and answer it is evident that the question asked for a solution for a problem that didn’t exist. The answer said so, and the algorithm rated the answer high because it provided enough information. The participant might have thought the failure of not providing an answer for the question that has no solution as a failure of the system.The algorithm performed well in the user evaluation but still there is certain limitation of the system. The system uses keywords and categories to first find the subset of possible answers and then performs the text search. The limitation of the keyword annotator is the limitation of the search algorithm. The algorithm doesn’t perform full text search again to the remaining answers because of time and processing power restriction.Also, the system uses crowdsourced data and votes to rank the answers, so it is highly depended on people’s contribution. If there are malicious users or not enough votes then the algorithm is like a text search algorithm.Overall, the answers performed well and provided relevant solutions to the unanswered questions.

\subsection{Summary}